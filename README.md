# Toxic Comment Classifier
Submission for Advanced ML project (Silky and Rahim)

This project introduces various deep learning approaches applied to the task of classifying toxic messages. In particular, we attempt to use the Naive-Bayes model, Multi-Perceptron Model and Long-Short Term Memory networks to identify toxicity in online messages. We evaluated our approaches on Wikipedia comments from the Kaggle Toxic Comments Classification Challenge 2 dataset.  In addition to correctly classifying toxic messages, the project also attempts to identify and control for some of the identity biases that arise in labelling comments as toxic. Our assessment found that our forward LSTM model achieved the best performance on binary classification. Though best, the model does not perform as good as we had expected. It is only marginally better than the Naive Bayes model.

In this repository, we have added the pipeline for the baseline models including naive bayes a well as deep learning ones

