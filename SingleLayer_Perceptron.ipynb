{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AYZ8CefTFnrP"
      },
      "outputs": [],
      "source": [
        "#!pip install torchtext==0.11.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ORcQHQIgfc6c",
        "outputId": "e8d58969-4dfb-4fda-f152-59b19d31ca16"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tue May 24 16:44:08 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   37C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tR1AEopwHLQD",
        "outputId": "d351d3a3-c26c-4778-ef3c-ceb92e2f673d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('1.10.2+cu102', '0.11.2')"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "import torchtext\n",
        "torch.__version__, torchtext.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RkhS32N-HVmP",
        "outputId": "d16026db-9d57-491a-fa08-b14f99ec9d7d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from collections import Counter\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torchtext.legacy import data\n",
        "\n",
        "from google.colab import drive \n",
        "drive.mount('/content/gdrive')\n",
        "PATH = \"gdrive/My Drive/project_data/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XbTiKGe3HVoX"
      },
      "outputs": [],
      "source": [
        "from torchtext.vocab import vocab\n",
        "from torch.utils.data import DataLoader\n",
        "from itertools import combinations\n",
        "from torchtext.vocab import GloVe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "imma_uPDLthJ",
        "outputId": "ca9c6caa-33af-4d6d-c1ed-51d0c8de4d54"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ".vector_cache/glove.6B.zip: 862MB [02:39, 5.40MB/s]                           \n",
            "100%|█████████▉| 399999/400000 [00:34<00:00, 11684.25it/s]\n"
          ]
        }
      ],
      "source": [
        "glove = GloVe(name='6B')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BlT9ryXEHVqO"
      },
      "outputs": [],
      "source": [
        "SEED = 1515\n",
        "\n",
        "#random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(1515)\n",
        "torch.backends.cudnn.deterministic = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TMeYfRqvHVsP",
        "outputId": "ab5bca85-ca45-4482-ff4e-7c24d28bb6e9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oq4M3ObwHaLp"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(PATH+'train.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PWo0HoVdK3jk"
      },
      "outputs": [],
      "source": [
        "df['toxic'] = np.where(df['target'] > 0.5, 1, 0)\n",
        "data = df[['comment_text','toxic']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CV_BAdY5O3fg"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train, val = train_test_split(data, test_size=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m_482DntK3hr"
      },
      "outputs": [],
      "source": [
        "def custom_tokenize(text):\n",
        "    if not text:\n",
        "        return ''\n",
        "    return nltk.word_tokenize(text.lower())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A_r6j2lfK3fq"
      },
      "outputs": [],
      "source": [
        "train = list(train.to_records(index=False))\n",
        "val = list(val.to_records(index=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YZeZk93aK3bi"
      },
      "outputs": [],
      "source": [
        "def collate_into_cbow(batch):    \n",
        "    label_vec = []\n",
        "    cbow_vec = []\n",
        "    for idx, (txt, l) in enumerate(batch):\n",
        "        label_vec.append(l)\n",
        "        tokenized = custom_tokenize(txt)\n",
        "        vecs = glove.get_vecs_by_tokens(tokenized)\n",
        "        c_vecs = torch.div(vecs.sum(dim=0), vecs.size()[0])\n",
        "        c_vecs = c_vecs.unsqueeze(0)\n",
        "        if idx == 0:\n",
        "            cbow_vec = c_vecs\n",
        "        else:\n",
        "            cbow_vec = torch.cat([cbow_vec, c_vecs])\n",
        "\n",
        "    labels = torch.tensor(label_vec)    \n",
        "    return cbow_vec.to(device), labels.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rAmBC0gAHaRt",
        "outputId": "55ea729f-8aa4-46d1-bd06-798ba51895eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 torch.Size([64, 300]) torch.Size([64])\n",
            "1 torch.Size([64, 300]) torch.Size([64])\n",
            "2 torch.Size([64, 300]) torch.Size([64])\n"
          ]
        }
      ],
      "source": [
        "train_cbow = DataLoader(train, batch_size=64, shuffle=False, \n",
        "                        collate_fn=collate_into_cbow)\n",
        "\n",
        "val_cbow = DataLoader(train, batch_size=64, shuffle=False, \n",
        "                        collate_fn=collate_into_cbow)\n",
        "\n",
        "for idx, (lt, tt) in enumerate(train_cbow):\n",
        "    print(idx, lt.shape, tt.shape)\n",
        "    if idx == 2: break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Za9FzJeHaTq"
      },
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# task 6\n",
        "class cBoWClassifier(nn.Module):\n",
        "    \n",
        "    def __init__(self, num_labels, vocab_size):\n",
        "        super(cBoWClassifier, self).__init__()\n",
        "        self.linear = nn.Linear(vocab_size, 50)\n",
        "        self.hidden = nn.Linear(50, num_labels)\n",
        "        self.nonlinearity = nn.Tanh()\n",
        "\n",
        "    def forward(self, bow_vec):\n",
        "        out = self.nonlinearity(self.linear(bow_vec))\n",
        "        return F.log_softmax(self.hidden(out), dim=1)  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xRQSQAZQHaVo"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 64\n",
        "num_labels = 2\n",
        "vocab_size = 300\n",
        "model = cBoWClassifier(num_labels, vocab_size).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IdiKrDT1TtJZ"
      },
      "outputs": [],
      "source": [
        "def get_accuracy(dataloader):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        correct_pred = 0\n",
        "        total_samples = 0\n",
        "        correct_pos = 0\n",
        "        pos_samples = 0\n",
        "        for idx, (text, label) in enumerate(dataloader):\n",
        "            total_samples += text.size()[0]\n",
        "            log_probs = model(text)\n",
        "            predictions = torch.argmax(log_probs, dim=1)\n",
        "            correct_pred += torch.eq(predictions, label).long().sum().item()\n",
        "            pos_samples += torch.sum(predictions).float()\n",
        "    return (correct_pred/total_samples, correct_pred/pos_samples)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RLoBmZVkT04X"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "loss_function = torch.nn.NLLLoss()\n",
        "\n",
        "def train_an_epoch(dataloader):\n",
        "    model.train() # Sets the module in training mode.\n",
        "    log_interval = 5000\n",
        "\n",
        "    for idx, (text, label) in enumerate(dataloader):\n",
        "        model.zero_grad()\n",
        "        log_probs = model(text)\n",
        "        loss = loss_function(log_probs, label)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if idx % log_interval == 0 and idx > 0:\n",
        "            print(f'At iteration {idx} the loss is {loss:.3f}.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "yTIb8L7BT3Rj",
        "outputId": "ec648bcc-3f81-4799-edc5-561f2f6968cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "At iteration 5000 the loss is 0.928.\n",
            "At iteration 10000 the loss is 0.670.\n",
            "At iteration 15000 the loss is 4.736.\n",
            "At iteration 20000 the loss is 1.292.\n",
            "\n",
            "After epoch 1 the validation accuracy is 0.908.\n",
            "After epoch 1 the validation precision is 12.154.\n",
            "\n",
            "At iteration 5000 the loss is 0.737.\n",
            "At iteration 10000 the loss is 0.132.\n",
            "At iteration 15000 the loss is 4.434.\n",
            "At iteration 20000 the loss is 1.366.\n",
            "\n",
            "After epoch 2 the validation accuracy is 0.941.\n",
            "After epoch 2 the validation precision is 12820.066.\n",
            "\n",
            "At iteration 5000 the loss is 2.419.\n",
            "At iteration 10000 the loss is 0.284.\n",
            "At iteration 15000 the loss is 4.343.\n",
            "At iteration 20000 the loss is 1.180.\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "EPOCHS = 3 # epoch\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=3)\n",
        "\n",
        "accuracies=[]\n",
        "precisions =[]\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    epoch_start_time = time.time()\n",
        "    train_an_epoch(train_cbow)\n",
        "    accuracy, precision = get_accuracy(val_cbow)\n",
        "    accuracies.append(accuracy)\n",
        "    precisions.append(precision)\n",
        "    time_taken = time.time() - epoch_start_time\n",
        "    print()\n",
        "    print(f'After epoch {epoch} the validation accuracy is {accuracy:.3f}.')\n",
        "    print(f'After epoch {epoch} the validation precision is {precision:.3f}.')\n",
        "    print()\n",
        "    \n",
        "plt.plot(range(1, EPOCHS+1), accuracies)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AvT8t385CvfD"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "name": "SingleLayer_Perceptron.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}